<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Accurate SVG filters for color blindness simulation</h1><p class="page-description">Protanopia and deuteranopia are easy to implement with a single matrix multiplication, but tritanopia requires special care and a more subtle pipeline. Let's see how we can still implement the state-of-the-art approach of Brettel et al. with SVG filters.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-25T00:00:00-06:00" itemprop="datePublished">
        Nov 25, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#introduction">Introduction</a></li>
<li class="toc-entry toc-h1"><a href="#starting-easy-implementing-the-viénot-1999-filter">Starting easy, implementing the Viénot 1999 filter</a></li>
<li class="toc-entry toc-h1"><a href="#implementing-brettel-1997">Implementing Brettel 1997</a></li>
<li class="toc-entry toc-h1"><a href="#conclusion">Conclusion</a></li>
<li class="toc-entry toc-h1"><a href="#bibliography">Bibliography</a></li>
</ul><h1 id="introduction">
<a class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h1>

<p>We have seen in <a href="opensource-cvd-simulation/">Review of Open Source Color Blindness
Simulations</a> and <a href="understanding-cvd-simulation/">Understanding LMS-based Color
Blindness Simulations</a> that a pretty accurate
simulation of the 3 main color vision deficiencies (protanopia, deuteranopia and
tritanopia) can be achieved by the <a class="citation" href="#brettel_computerized_1997">(Brettel, Viénot, &amp; Mollon, 1997)</a> method,
and that a simpler viable algorithm for protanopia and deuteranopia is given by
<a class="citation" href="#vienot_digital_1999">(Viénot, Brettel, &amp; Mollon, 1999)</a>.</p>

<p>Being able to do the CVD simulation via <a href="https://www.w3schools.com/graphics/svg_filters_intro.asp">SVG
filters</a> is very handy
to enable efficient browser extension (eg.
<a href="https://github.com/oftheheadland/Colorblindly">Colorblindly</a>) or even to
implement the <a href="https://developer.chrome.com/blog/cvd/">developer tools in Google
Chrome</a> or Mozilla Firefox. This makes
it easy for web developers to check if their design is color blind
friendly.</p>

<p>The SVG filters primitives are quite limited though, mostly matrix
multiplication, convolution and blending.</p>

<p>The good news is that these CVD algorithms are pretty simple to implement,
especially the Viénot 1999 one. It ends up being a single 3x3 matrix
multiplication of the linear rgb values.</p>

<p>However the Brettel 1997 one is required for accurate tritanopia simulation, but
unfortunately it’s a bit more complex. The direct implementation needs to
convert the RGB values to the LMS color space (one 3x3 matrix multiplication),
apply a dot product with the normal of the separation plane to choose one
projection matrix among two possibilities, apply the selected projection matrix
and go back to RGB from LMS (another 3x3 matrix multiplication). Let’s see how
we can still implement that with an SVG filter.</p>

<h1 id="starting-easy-implementing-the-viénot-1999-filter">
<a class="anchor" href="#starting-easy-implementing-the-vi%C3%A9not-1999-filter" aria-hidden="true"><span class="octicon octicon-link"></span></a>Starting easy, implementing the Viénot 1999 filter</h1>

<p>The overall setup of the CSS + SVG properties in HTML is not our main topic
here, so I’ll refer to e.g. <a href="https://developer.chrome.com/blog/cvd/">Simulating color vision deficiencies in the Blink
Renderer</a> if you want more details.</p>

<p>A reference html page is available in
<a href="https://github.com/DaltonLens/libDaltonLens/blob/master/svg/cvd_svg_filters.html">libDaltonLens</a>,
which can be visualized directly <a href="https://daltonlens.github.io/libDaltonLens/svg/cvd_svg_filters.html">in this live
demo</a>.</p>

<p>This is what the code looks like for protanopia:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;filter id="protanopia" color-interpolation-filters="linearRGB"&gt;
    &lt;feColorMatrix type="matrix" in="SourceGraphic" values="
        0.10889,0.89111,-0.00000,0,0
        0.10889,0.89111,0.00000,0,0
        0.00447,-0.00447,1.00000,0,0
        0,0,0,1,0"
    /&gt;
&lt;/filter&gt;
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">feColorMatrix</code> specifies a 4x5 matrix that takes a vector <code class="language-plaintext highlighter-rouge">[R G B A 1]</code> and
returns the transformed <code class="language-plaintext highlighter-rouge">[R' G' B' A']</code>. As we’ve seen in previous articles it
is very important that the filter happens in the linear RGB space, hence the
<code class="language-plaintext highlighter-rouge">color-interpolation-filters="linearRGB"</code> attribute. It should be the default,
but it never hurts to be explicit.</p>

<p>Here the matrix content was dumped from <a href="https://github.com/DaltonLens/DaltonLens-Python">DaltonLens-Python</a>, and it corresponds to a combined sequence of going from RGB to LMS, applying a projection and going back to RGB.</p>

<h1 id="implementing-brettel-1997">
<a class="anchor" href="#implementing-brettel-1997" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implementing Brettel 1997</h1>

<p>Instead of a single projection matrix, Brettel 1997 needs two, one for each half-plane in the LMS space. Here is the pseudo-code:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>lms = LMS_from_RGB . rgb
H = (planeSepNormal^t . lms  &gt;= 0) ? H1 : H2
lms_cvd = H . lms
rgb_cvd = RGB_from_LMS . lms_cvd
</code></pre></div></div>

<p>with <code class="language-plaintext highlighter-rouge">LMS_from_RGB, RGB_from_LMS, H1 and H2</code> some constant 3x3 matrices (only depends on the CVD type), and <code class="language-plaintext highlighter-rouge">planeSepNormal</code> a 3d vector representing the normal of the separation plane in the LMS space.</p>

<p>We don’t really have convenient conditionals with SVG filters, so it’s not
straightforward to adapt. But first we can simplify this pipeline by combining
the two possible sequences into just two 3x3 matrices:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>rgb_cvd_from_rgb_1 = RGB_from_LMS . H1 . LMS_from_RGB
rgb_cvd_from_rgb_2 = RGB_from_LMS . H2 . LMS_from_RGB
</code></pre></div></div>

<p>Then our problem becomes to choose between these two, and this can also be written without explicitly going to LMS:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>planeSepNormal . lms = planeSepNormal^t . LMS_from_RGB . rgb
                     = planeSepNormal_rgb . rgb
</code></pre></div></div>

<p><code class="language-plaintext highlighter-rouge">planeSepNormal_rgb</code> is still a constant 3d vector and it can be precomputed. Now the overall pipeline becomes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>H = (planeSepNormal_rgb . rgb &gt;= 0) ? rgb_cvd_from_rgb_1 : rgb_cvd_from_rgb_2
rgb_cvd = H . rgb
</code></pre></div></div>

<p>Ok, that seems easier! The feature which is the closest to a conditional in the SVG filter is <code class="language-plaintext highlighter-rouge">feBlend</code>. It takes two images as an input, and will combine then depending on the alpha values of each image. So instead of applying a conditional to each pixel, we can just generate two images, one with <code class="language-plaintext highlighter-rouge">rgb_cvd_from_rgb_1</code>, another one with <code class="language-plaintext highlighter-rouge">rgb_cvd_from_rgb_2</code>, and make sure that the first image has <code class="language-plaintext highlighter-rouge">alpha=1</code> when we should indeed pick the pixel from that first image, and <code class="language-plaintext highlighter-rouge">alpha=0</code> when we should take the value from the second image.</p>

<p>Our condition is <code class="language-plaintext highlighter-rouge">(planeSepNormal_rgb . rgb &gt;= 0)</code>, we just need to transform that into an <code class="language-plaintext highlighter-rouge">alpha</code> that is either 0 or 1. Computing <code class="language-plaintext highlighter-rouge">alpha = planeSepNormal_rgb . rgb</code> is easy, we can just add <code class="language-plaintext highlighter-rouge">planeSepNormal_rgb</code> to the fourth row of the <code class="language-plaintext highlighter-rouge">feColorMatrix</code>. But then we need to threshold that so that alpha becomes 1 if it’s higher than 0.</p>

<p>The primitive we can use to threshold is <code class="language-plaintext highlighter-rouge">feComponentTransfer</code> and <code class="language-plaintext highlighter-rouge">feFunc</code>. It has a <code class="language-plaintext highlighter-rouge">discrete</code> mode that can map slices of the input range into specific values. For example <code class="language-plaintext highlighter-rouge">&lt;feFuncA type="discrete" tableValues="0 1"/&gt;</code> would split the input range in two, and transform the alpha channel such that values between 0 and 0.5 become 0 and values between 0.5 and 1 become 1.</p>

<p>So one idea is to make the fourth row of <code class="language-plaintext highlighter-rouge">feColorMatrix</code> also include a 0.5 offset, such that <code class="language-plaintext highlighter-rouge">alpha = planeSepNormal_rgb . rgb + 0.5</code>. Then we can threshold that: values below 0.5 to 0 and values above it to 1.</p>

<p>This almost works, but has two caveats:</p>

<ul>
  <li>
    <p>The original alpha information is lost. So this only works if the input graphics is fully opaque. Even worse, there is a weird situation with Google Chrome where some extra padding with zero transparency will get transformed (sounds like a bug). We can workaround that one by keeping the original alpha, but <em>subtracting</em> 0.5 to it. This way if it was zero, it’ll remain zero.</p>
  </li>
  <li>
    <p>Images are stored as 32 bit RGBA (8 bit per channel) with premultiplied alpha, which means that the intermediate rgb will be multiplied by a value centered around 0.5 and clamped + rounded to [0,255]. To avoid losing too much precision we can make it a bit higher, e.g. 0.8 and use a threshold that transforms values higher than 0.8 into 1 with <code class="language-plaintext highlighter-rouge">&lt;feFuncA type="discrete" tableValues="0 0 0 0 1"/&gt;</code>.</p>
  </li>
</ul>

<p>Combined together, we get this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;filter id="tritanopia" color-interpolation-filters="linearRGB"&gt;    
&lt;!-- 
    Projection on plane 1. 
    alpha &lt; 0.8 means we should use the projection on plane 2 
--&gt;
&lt;feColorMatrix type="matrix" in="SourceGraphic" result="ProjectionOnPlane1" values="
    1.01354, 0.14268, -0.15622, 0, 0
    -0.01181, 0.87561, 0.13619, 0, 0
    0.07707, 0.81208, 0.11085, 0, 0
    7.92482, -5.66475, -2.26007, 1, -0.2"
    &lt;!-- That last row is computing alpha --&gt;
/&gt;
&lt;!-- 
    Binarize alpha. 5 values means the last chunk will start at 0.8.
    All the values below 0.8 will become 0 (correspond to the dot
    product with the separation plane being negative) and above will become 1
--&gt;        
&lt;feComponentTransfer in="ProjectionOnPlane1" result="ProjectionOnPlane1"&gt;
    &lt;feFuncA type="discrete" tableValues="0 0 0 0 1"/&gt;
&lt;/feComponentTransfer&gt;

&lt;!-- Project on the second plane. --&gt;
&lt;feColorMatrix type="matrix" in="SourceGraphic" result="ProjectionOnPlane2" values="
    0.93337, 0.19999, -0.13336, 0, 0
    0.05809, 0.82565, 0.11626, 0, 0
    -0.37923, 1.13825, 0.24098, 0, 0
    0,0,0,1,0"
/&gt;

&lt;!-- Blend the two projections, picking one or the other depending on alpha. --&gt;
&lt;feBlend in="ProjectionOnPlane1" in2="ProjectionOnPlane2" mode="normal"/&gt;
&lt;/filter&gt;
</code></pre></div></div>

<h1 id="conclusion">
<a class="anchor" href="#conclusion" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusion</h1>

<p>This filter does the job overall for opaque content and is pretty efficient. We still need to address the loss of the alpha channel to actually use it to render entire webpages. I tried to play around with an additional blending to transfer the alpha channel of the source image to the final image, but without success so far, and I ran out of time for this experiment. Let me know if you have an idea!</p>

<h1 id="bibliography">
<a class="anchor" href="#bibliography" aria-hidden="true"><span class="octicon octicon-link"></span></a>Bibliography</h1>

<ol class="bibliography">
<li><span id="brettel_computerized_1997">Brettel, H., Viénot, F., &amp; Mollon, J. D. (1997). Computerized simulation of color appearance for dichromats. <i>Journal of the Optical Society of America. A, Optics, Image Science, and Vision</i>, <i>14</i>(10), 2647–2655. https://doi.org/10.1364/josaa.14.002647</span></li>
<li><span id="vienot_digital_1999">Viénot, F., Brettel, H., &amp; Mollon, J. D. (1999). Digital video colourmaps for checking the legibility of displays by dichromats. <i>Color Research &amp; Application</i>, <i>24</i>(4), 243–252.</span></li>
</ol>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="DaltonLens/daltonlens.org"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/cvd-simulation-svg-filters/" hidden></a>
</article>